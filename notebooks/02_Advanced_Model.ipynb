{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Model (XGBoost)\n",
    "\n",
    "This notebook implements an advanced model using XGBoost with extensive feature engineering.\n",
    "\n",
    "## Steps:\n",
    "1. Load Data\n",
    "2. Feature Engineering\n",
    "    - Amenities (Count, Top items)\n",
    "    - Text Features (TF-IDF on Name)\n",
    "    - Bathrooms extraction\n",
    "    - Categorical Encoding\n",
    "3. Train XGBoost Model (CV)\n",
    "4. Evaluate (RMSE)\n",
    "5. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-3.1.2-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from xgboost) (1.15.3)\n",
      "Using cached xgboost-3.1.2-py3-none-macosx_12_0_arm64.whl (2.2 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (24153, 58)\n",
      "Test shape: (4750, 56)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combined for processing.\n"
     ]
    }
   ],
   "source": [
    "# Clean price\n",
    "def clean_price(price):\n",
    "    if isinstance(price, str):\n",
    "        return float(price.replace('$', '').replace(',', ''))\n",
    "    return price\n",
    "\n",
    "train_df['price'] = train_df['price'].apply(clean_price)\n",
    "train_df = train_df.dropna(subset=['price'])\n",
    "train_df['log_price'] = np.log1p(train_df['price'])\n",
    "\n",
    "# Combine for processing\n",
    "train_len = len(train_df)\n",
    "all_data = pd.concat([train_df.drop(['price', 'log_price'], axis=1), test_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(\"Data combined for processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Bathrooms\n",
    "def extract_bathrooms(text):\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)', str(text))\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan\n",
    "\n",
    "all_data['bathrooms_count'] = all_data['bathrooms_text'].apply(extract_bathrooms)\n",
    "# Fill missing bathrooms with median\n",
    "all_data['bathrooms_count'] = all_data['bathrooms_count'].fillna(all_data['bathrooms_count'].median())\n",
    "\n",
    "# 2. Host Superhost\n",
    "all_data['host_is_superhost'] = all_data['host_is_superhost'].map({'t': 1, 'f': 0}).fillna(0)\n",
    "\n",
    "# 3. Amenities\n",
    "all_data['amenities'] = all_data['amenities'].fillna('[]')\n",
    "all_data['amenities_count'] = all_data['amenities'].apply(lambda x: len(str(x).split(',')))\n",
    "\n",
    "# Top amenities\n",
    "top_amenities = ['Wifi', 'Air conditioning', 'Kitchen', 'Heating', 'Washer', 'Dryer', 'Essentials', \n",
    "                 'Shampoo', 'Hangers', 'Iron', 'TV', 'Hot water', 'Hair dryer', 'Refrigerator', \n",
    "                 'Dishes and silverware', 'Cooking basics', 'Oven', 'Stove', 'Microwave', 'Coffee maker']\n",
    "\n",
    "for amenity in top_amenities:\n",
    "    all_data[f'amenity_{amenity}'] = all_data['amenities'].apply(lambda x: 1 if amenity in str(x) else 0)\n",
    "\n",
    "print(\"Amenities processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text features...\n"
     ]
    }
   ],
   "source": [
    "# 4. Text Features (TF-IDF)\n",
    "print(\"Processing text features...\")\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "# max_features=50: Keep only the top 50 most frequent words to avoid high dimensionality\n",
    "# stop_words='english': Remove common English words (e.g., 'the', 'is') that don't add value\n",
    "tfidf_name = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "\n",
    "# Fit and transform the 'name' column\n",
    "# fillna('') handles missing values by replacing them with empty strings\n",
    "name_features = tfidf_name.fit_transform(all_data['name'].fillna(''))\n",
    "\n",
    "# Convert the resulting sparse matrix to a DataFrame\n",
    "# Columns are named 'name_tfidf_0' to 'name_tfidf_49'\n",
    "name_df = pd.DataFrame(name_features.toarray(), columns=[f'name_tfidf_{i}' for i in range(50)])\n",
    "\n",
    "# Concatenate the new features with the original data\n",
    "all_data = pd.concat([all_data, name_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 92\n"
     ]
    }
   ],
   "source": [
    "# 5. Categorical Encoding\n",
    "cat_cols = ['room_type', 'neighbourhood_group_cleansed', 'property_type']\n",
    "# Simplify property type (keep top 10, others 'Other')\n",
    "top_properties = all_data['property_type'].value_counts().head(10).index\n",
    "all_data['property_type'] = all_data['property_type'].apply(lambda x: x if x in top_properties else 'Other')\n",
    "\n",
    "all_data = pd.get_dummies(all_data, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# 6. Numerical Features\n",
    "num_cols = ['accommodates', 'bedrooms', 'beds', 'minimum_nights', 'calculated_host_listings_count', \n",
    "            'review_scores_rating', 'bathrooms_count', 'amenities_count', 'host_is_superhost']\n",
    "\n",
    "# Fill missing numericals\n",
    "for col in num_cols:\n",
    "    if col in all_data.columns:\n",
    "        all_data[col] = all_data[col].fillna(all_data[col].median())\n",
    "\n",
    "# Select features for model\n",
    "feature_cols = num_cols + [c for c in all_data.columns if c.startswith('amenity_') or c.startswith('name_tfidf_') or c.startswith('room_type_') or c.startswith('neighbourhood_group_') or c.startswith('property_type_')]\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "Fold 1 RMSE: 0.5475474477421488\n",
      "Fold 2 RMSE: 0.5205557528544259\n",
      "Fold 3 RMSE: 0.5621941390505845\n",
      "Fold 4 RMSE: 0.5591110468535713\n",
      "Fold 5 RMSE: 0.5298412096916764\n",
      "Average RMSE: 0.5438499192384814\n"
     ]
    }
   ],
   "source": [
    "# Split back\n",
    "X = all_data.iloc[:train_len][feature_cols]\n",
    "y = train_df['log_price']\n",
    "X_test = all_data.iloc[train_len:][feature_cols]\n",
    "\n",
    "# Validation\n",
    "print(\"Training XGBoost model...\")\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=500, learning_rate=0.05, max_depth=6, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "    print(f\"Fold {fold+1} RMSE: {rmse}\")\n",
    "\n",
    "print(f\"Average RMSE: {np.mean(rmse_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission...\n",
      "Submission saved to ../submissions/advanced_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Final prediction\n",
    "print(\"Generating submission...\")\n",
    "final_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=500, learning_rate=0.05, max_depth=6, random_state=42, n_jobs=-1)\n",
    "final_model.fit(X, y)\n",
    "y_pred_test_log = final_model.predict(X_test)\n",
    "y_pred_test = np.expm1(y_pred_test_log)\n",
    "\n",
    "submission = pd.DataFrame({'ID': test_df['id'], 'TARGET': y_pred_test})\n",
    "if not os.path.exists('../submissions'):\n",
    "    os.makedirs('../submissions')\n",
    "submission.to_csv('../submissions/advanced_submission.csv', index=False)\n",
    "print(\"Submission saved to ../submissions/advanced_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}